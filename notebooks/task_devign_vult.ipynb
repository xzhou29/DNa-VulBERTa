{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "from tokenizers import *\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "# from tokenizers.processors import BertProcessing\n",
    "import numpy as np\n",
    "import models\n",
    "from models import DefectModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPORTANT\n",
    "# out_dir = './task_devign_v3'\n",
    "# raw_data_path = '/scratch/xin/devign_task/tokenized_devign_v3.pkl'\n",
    "# model_path = '/scratch/xin/bert_source_v3/pretrained-bert/'\n",
    "num_epochs = 1\n",
    "max_step_saves = 3\n",
    "save_step_at = 1000\n",
    "learning_rate = 1e-5\n",
    "adam_epsilon = 1e-8\n",
    "early_stop = 10\n",
    "normalize = 'ReLU'\n",
    "test_only = False\n",
    "data_type = 'devign'\n",
    "\n",
    "# # redas-lab2\n",
    "MAX_LENGTH = 512\n",
    "data_dir = \"/scratch/dna_data_vult/\"\n",
    "# vult_model_path = '../pretrained-dna-vult/checkpoint-80'\n",
    "vult_model_path = 'Salesforce/codet5-base'\n",
    "tokenizer_path = \"Salesforce/codet5-base\"\n",
    "batch_size = 2  # 8GB per GPU   \n",
    "\n",
    "# # # carya cluster\n",
    "# MAX_LENGTH = 1024\n",
    "# data_dir = \"../../dna_data_lite_2/{}\".format(data_type)\n",
    "# bert_model_path = '../pretrained-dna-roberta-2/checkpoint-40000'\n",
    "# tokenizer_path = '../../dna_data_pretraining_2/BPE_tokenizer'\n",
    "# batch_size = 16 # 32GB per GPU -  max_length 512: 32 -max_length 1024: 16\n",
    "\n",
    "out_dir = '../result_duo_mode_{}_{}_with_tagging'.format(data_type, MAX_LENGTH)\n",
    "truncate_longer_samples = True\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "log_txt_file = os.path.join(out_dir, 'log.txt')\n",
    "# intialization\n",
    "with open(log_txt_file, 'w+') as f:\n",
    "    f.write('- log -\\n')\n",
    "\n",
    "def log_txt(s, type='normal'):\n",
    "    with open(log_txt_file, 'a') as f:\n",
    "        f.write('{} - {}\\n'.format( type, s))\n",
    "\n",
    "# intial parameters\n",
    "log_txt('data_type: {}'.format(data_type))\n",
    "log_txt('data_dir: {}'.format(data_dir))\n",
    "log_txt('out_dir: {}'.format(out_dir))\n",
    "# log_txt('bert_model_path: {}'.format(bert_model_path))\n",
    "log_txt('tokenizer_path: {}'.format(tokenizer_path))\n",
    "log_txt('MAX_LENGTH: {}'.format(MAX_LENGTH))\n",
    "log_txt('batch_size: {}'.format(batch_size))\n",
    "log_txt('num_epochs: {}'.format(num_epochs))\n",
    "log_txt('save_step_at: {}'.format(save_step_at))\n",
    "log_txt('learning_rate: {}'.format(learning_rate))\n",
    "log_txt('adam_epsilon: {}'.format(adam_epsilon))\n",
    "log_txt('normalize: {}'.format(normalize))\n",
    "# log_txt('CLASSIFIER_HIDDEN_SIZE: {}'.format(CLASSIFIER_HIDDEN_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data(file_path):\n",
    "    raw_df = pd.read_pickle(file_path)  \n",
    "    df = {'filename': [], 'code': [], 'nat': [], 'tags': [], 'label': []}\n",
    "    for i in range(len(raw_df['code'][:100])):\n",
    "        df['filename'].append(raw_df['filename'][i])\n",
    "        ## add \"Defect: \" is required to switch VulT model for specific task\n",
    "        df['code'].append('Defect: ' + raw_df['code'][i])\n",
    "        df['nat'].append('Defect: ' +raw_df['nat'][i])\n",
    "        df['tags'].append('Defect: ' +raw_df['tags'][i])\n",
    "        df['label'].append(raw_df['label'][i])\n",
    "        \n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "    ### convert to Huggingface dataset\n",
    "#     return Dataset(pa.Table.from_pandas(df))\n",
    "\n",
    "# random split into train/valid/test\n",
    "if data_type == 'devign':\n",
    "    train_data = get_data(os.path.join(data_dir, 'devign_train.pkl'))\n",
    "    valid_data = get_data(os.path.join(data_dir, 'devign_valid.pkl'))\n",
    "    test_data = get_data(os.path.join(data_dir, 'devign_test.pkl'))\n",
    "elif data_type == 'd2a':\n",
    "    train_data = get_data(os.path.join(data_dir, 'd2a_train.pkl'))\n",
    "    valid_data = get_data(os.path.join(data_dir, 'd2a_dev.pkl'))\n",
    "    test_data = get_data(os.path.join(data_dir, 'd2a_dev.pkl'))\n",
    "# # load train/valid/test\n",
    "# elif data_type in ['mvdsc', 'd2a' ]:\n",
    "#     train_data = get_data(os.path.join(data_dir, 'train.pkl'))\n",
    "#     valid_data = get_data(os.path.join(data_dir, 'valid.pkl'))\n",
    "#     test_data = get_data(os.path.join(data_dir, 'test.pkl'))\n",
    "# # load train/valid/test from 4 types\n",
    "# elif data_type in ['sysevr']:\n",
    "#     # already randomized from pre-processing with fixed seed for pre-training and fine-tuning\n",
    "#     raw_data_path = os.path.join(data_dir, 'api.pkl')\n",
    "#     tokenized_data = get_data(raw_data_path)\n",
    "#     train_data_1, valid_data_1, test_data_1 = np.split(tokenized_data, [int(.7*len(tokenized_data)), int(.85*len(tokenized_data))])\n",
    "#     raw_data_path = os.path.join(data_dir, 'au.pkl')\n",
    "#     tokenized_data = get_data(raw_data_path)\n",
    "#     train_data_2, valid_data_2, test_data_2 = np.split(tokenized_data, [int(.7*len(tokenized_data)), int(.85*len(tokenized_data))])\n",
    "#     raw_data_path = os.path.join(data_dir, 'ae.pkl')\n",
    "#     tokenized_data = get_data(raw_data_path)\n",
    "#     train_data_3, valid_data_3, test_data_3 = np.split(tokenized_data, [int(.7*len(tokenized_data)), int(.85*len(tokenized_data))])\n",
    "#     raw_data_path = os.path.join(data_dir, 'pu.pkl')\n",
    "#     tokenized_data = get_data(raw_data_path)\n",
    "#     train_data_4, valid_data_4, test_data_4 = np.split(tokenized_data, [int(.7*len(tokenized_data)), int(.85*len(tokenized_data))])\n",
    "#     tokenized_data = get_data(raw_data_path)\n",
    "#     train_data = pd.concat([train_data_1, train_data_2, train_data_3, train_data_4], ignore_index=True)\n",
    "#     valid_data = pd.concat([valid_data_1, valid_data_2, valid_data_3, valid_data_4], ignore_index=True)\n",
    "#     test_data = pd.concat([test_data_1, test_data_2, test_data_3, test_data_4], ignore_index=True)\n",
    "# elif  data_type in ['draper']:\n",
    "#     # splitted data bc too large\n",
    "#     all_data = {}\n",
    "#     for i in range(10):\n",
    "#         raw_data_path = os.path.join(data_dir, 'train_{}.pkl'.format(i))\n",
    "#         tokenized_data = get_data(raw_data_path)\n",
    "#         #train_data = pd.concat([train_data_1, train_data_2, train_data_3, train_data_4], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    print('data type does not exist!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 5)\n",
      "(100, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Defect: static uint32_t sh_serial_ioport_read(void *opaque, uint32_t offs) newline { newline sh_serial_state *s = opaque; newline uint32_t ret = ~0; newline #if 0 newline switch(offs) { newline case 0x00: newline ret = s->smr; newline break; newline case 0x04: newline ret = s->brr; newline break; newline case 0x08: newline ret = s->scr; newline break; newline case 0x14: newline ret = 0; newline break; newline } newline #endif newline if (s->feat & SH_SERIAL_FEAT_SCIF) { newline switch(offs) { newline case 0x00: /* SMR */ newline ret = s->smr; newline break; newline case 0x08: /* SCR */ newline ret = s->scr; newline break; newline case 0x10: /* FSR */ newline ret = 0; newline if (s->flags & SH_SERIAL_FLAG_TEND) newline ret |= (1 << 6); newline if (s->flags & SH_SERIAL_FLAG_TDE) newline ret |= (1 << 5); newline if (s->flags & SH_SERIAL_FLAG_BRK) newline ret |= (1 << 4); newline if (s->flags & SH_SERIAL_FLAG_RDF) newline ret |= (1 << 1); newline if (s->flags & SH_SERIAL_FLAG_DR) newline ret |= (1 << 0); newline if (s->scr & (1 << 5)) newline s->flags |= SH_SERIAL_FLAG_TDE | SH_SERIAL_FLAG_TEND; newline break; newline case 0x14: newline if (s->rx_cnt > 0) { newline ret = s->rx_fifo[s->rx_tail++]; newline s->rx_cnt--; newline if (s->rx_tail == SH_RX_FIFO_LENGTH) newline s->rx_tail = 0; newline if (s->rx_cnt < s->rtrg) newline s->flags &= ~SH_SERIAL_FLAG_RDF; newline } newline break; newline #if 0 newline case 0x18: newline ret = s->fcr; newline break; newline #endif newline case 0x1c: newline ret = s->rx_cnt; newline break; newline case 0x20: newline ret = s->sptr; newline break; newline case 0x24: newline ret = 0; newline break; newline } newline } newline else { newline #if 0 newline switch(offs) { newline case 0x0c: newline ret = s->dr; newline break; newline case 0x10: newline ret = 0; newline break; newline case 0x14: newline ret = s->rx_fifo[0]; newline break; newline case 0x1c: newline ret = s->sptr; newline break; newline } newline #endif newline } newline #ifdef DEBUG_SERIAL newline printf(\"sh_serial: read offs=0x%02x val=0x%x\\\\n\", newline offs, ret); newline #endif newline if (ret & ~((1 << 16) - 1)) { newline fprintf(stderr, \"sh_serial: unsupported read from 0x%02x\\\\n\", offs); newline assert(0); newline } newline return ret; newline } newline'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(test_data.shape)\n",
    "# print(train_data['code'][:3])\n",
    "log_txt('train: {} - valid: {} - test: {} '.format(len(train_data), len(valid_data), len(test_data)))\n",
    "train_data['code'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code = train_data['code'].values\n",
    "train_nat = train_data['nat'].values\n",
    "train_tags = train_data['tags'].values\n",
    "train_labels = train_data['label'].values\n",
    "\n",
    "valid_code = valid_data['code'].values\n",
    "valid_nat = valid_data['nat'].values\n",
    "valid_tags = valid_data['tags'].values\n",
    "valid_labels = valid_data['label'].values\n",
    "\n",
    "test_code = test_data['code'].values\n",
    "test_nat = test_data['nat'].values\n",
    "test_tags = test_data['tags'].values\n",
    "test_labels = test_data['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "train_texts = train_code\n",
    "log_txt('---------- train_code ---------------')\n",
    "text_lengths = [len(train_texts[i].split()) for i in range(len(train_texts))]\n",
    "log_txt('min: {}'.format(min(text_lengths)))\n",
    "log_txt('min: {}'.format(min(text_lengths)))\n",
    "log_txt('number of zeros:: {}'.format(len([item for item in text_lengths if item == 0])))\n",
    "log_txt('max: {}'.format(max(sorted(text_lengths))))\n",
    "log_txt('avg: {}'.format( sum(text_lengths) / len(text_lengths) ))\n",
    "log_txt('median: {}'.format( sorted(text_lengths)[len(text_lengths) // 2] ))\n",
    "log_txt('95%: {}'.format( sorted(text_lengths)[int(len(text_lengths)*0.95)]))\n",
    "log_txt('mean: {}'.format( statistics.mean(text_lengths)))\n",
    "log_txt('std: {}'.format( statistics.stdev(text_lengths)))\n",
    "\n",
    "train_texts = train_nat\n",
    "log_txt('---------- train_nat ---------------')\n",
    "text_lengths = [len(train_texts[i].split()) for i in range(len(train_texts))]\n",
    "log_txt('min: {}'.format(min(text_lengths)))\n",
    "log_txt('min: {}'.format(min(text_lengths)))\n",
    "log_txt('number of zeros:: {}'.format(len([item for item in text_lengths if item == 0])))\n",
    "log_txt('max: {}'.format(max(sorted(text_lengths))))\n",
    "log_txt('avg: {}'.format( sum(text_lengths) / len(text_lengths) ))\n",
    "log_txt('median: {}'.format( sorted(text_lengths)[len(text_lengths) // 2] ))\n",
    "log_txt('95%: {}'.format( sorted(text_lengths)[int(len(text_lengths)*0.95)]))\n",
    "log_txt('mean: {}'.format( statistics.mean(text_lengths)))\n",
    "log_txt('std: {}'.format( statistics.stdev(text_lengths)))\n",
    "\n",
    "\n",
    "train_texts = train_tags\n",
    "log_txt('---------- train_tags ---------------')\n",
    "text_lengths = [len(train_texts[i].split()) for i in range(len(train_texts))]\n",
    "log_txt('min: {}'.format(min(text_lengths)))\n",
    "log_txt('min: {}'.format(min(text_lengths)))\n",
    "log_txt('number of zeros:: {}'.format(len([item for item in text_lengths if item == 0])))\n",
    "log_txt('max: {}'.format(max(sorted(text_lengths))))\n",
    "log_txt('avg: {}'.format( sum(text_lengths) / len(text_lengths) ))\n",
    "log_txt('median: {}'.format( sorted(text_lengths)[len(text_lengths) // 2] ))\n",
    "log_txt('95%: {}'.format( sorted(text_lengths)[int(len(text_lengths)*0.95)]))\n",
    "log_txt('mean: {}'.format( statistics.mean(text_lengths)))\n",
    "log_txt('std: {}'.format( statistics.stdev(text_lengths)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28983/280788245.py:8: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(text_lengths, hist=True, kde=False,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# matplotlib histogram\n",
    "plt.hist(text_lengths, color = 'blue', edgecolor = 'black',\n",
    "         bins = int(180/5))\n",
    "# seaborn histogram\n",
    "sns.distplot(text_lengths, hist=True, kde=False, \n",
    "             bins=int(180/5), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# Add labels\n",
    "plt.title('Histogram of text length analysis')\n",
    "plt.xlabel('text length')\n",
    "plt.ylabel('counts')\n",
    "plt.savefig(os.path.join(out_dir, 'histogram.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salesforce/codet5-base\n"
     ]
    }
   ],
   "source": [
    "# ========================= load tokenizer START =========================\n",
    "# 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "# vocab_size = 32010\n",
    "# maximum sequence length, lowering will result to faster training (when increasing batch size)\n",
    "import sentencepiece as spm\n",
    "import transformers \n",
    "# !pip install sentencepiece\n",
    "print(tokenizer_path)\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "if 'codet5' in tokenizer_path:\n",
    "    tokenizer = transformers.RobertaTokenizer.from_pretrained(tokenizer_path)\n",
    "elif 'albert' in tokenizer_path:\n",
    "    tokenizer = transformers.AlbertTokenizer.from_pretrained(tokenizer_path)\n",
    "else:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "log_txt('tokenizer_path: {}\\n'.format( tokenizer_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "#     model_inputs = tokenizer(examples[\"text\"], max_length=max_length, padding=True, truncation=True)\n",
    "#     # Setup the tokenizer for targets\n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         labels = tokenizer(examples[\"label\"], max_length=max_length, padding=True, truncation=True)\n",
    "#     model_inputs[\"decoder_input_ids\"] = labels[\"input_ids\"]\n",
    "#     model_inputs[\"decoder_attention_mask\"] = labels[\"attention_mask\"]    \n",
    "#     # model_inputs[\"labels\"] =  labels[\"input_ids\"]\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "##### train data\n",
    "train_code_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in train_code]\n",
    "train_nat_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in train_nat]\n",
    "train_tags_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in train_tags]\n",
    "train_code_ids = [text_id['input_ids'] for text_id in train_code_dict]\n",
    "train_code_masks = [text_id['attention_mask'] for text_id in train_code_dict]\n",
    "train_nat_ids = [text_id['input_ids'] for text_id in train_nat_dict]\n",
    "train_nat_masks = [text_id['attention_mask'] for text_id in train_nat_dict]\n",
    "train_tag_ids = [text_id['input_ids'] for text_id in train_tags_dict]\n",
    "train_tag_masks = [text_id['attention_mask'] for text_id in train_tags_dict]\n",
    "\n",
    "train_x1, train_m1, train_x2, train_m2, train_x3, train_m3, train_y = train_code_ids, train_code_masks, train_nat_ids, train_nat_masks, train_tag_ids, train_tag_masks, train_labels\n",
    "train_x1 = torch.tensor(train_x1)\n",
    "train_m1 = torch.tensor(train_m1)\n",
    "train_x2 = torch.tensor(train_x2)\n",
    "train_m2 = torch.tensor(train_m2)\n",
    "train_x3 = torch.tensor(train_x3)\n",
    "train_m3 = torch.tensor(train_m3)\n",
    "train_y = torch.tensor(train_y)\n",
    "\n",
    "train_data = TensorDataset(train_x1, train_m1, train_x2, train_m2, train_x3, train_m3, train_y)\n",
    "train_sampler = list(range(len(train_data)))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "#### valid data\n",
    "valid_code_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in valid_code]\n",
    "valid_nat_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in valid_nat]\n",
    "valid_tags_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in valid_tags]\n",
    "valid_code_ids = [text_id['input_ids'] for text_id in valid_code_dict]\n",
    "valid_code_masks = [text_id['attention_mask'] for text_id in valid_code_dict]\n",
    "valid_nat_ids = [text_id['input_ids'] for text_id in valid_nat_dict]\n",
    "valid_nat_masks = [text_id['attention_mask'] for text_id in valid_nat_dict]\n",
    "valid_tag_ids = [text_id['input_ids'] for text_id in valid_tags_dict]\n",
    "valid_tag_masks = [text_id['attention_mask'] for text_id in valid_tags_dict]\n",
    "\n",
    "valid_x1, valid_m1, valid_x2, valid_m2, valid_x3, valid_m3, valid_y = valid_code_ids, valid_code_masks, valid_nat_ids, valid_nat_masks, valid_tag_ids, valid_tag_masks, valid_labels\n",
    "valid_x1 = torch.tensor(valid_x1)\n",
    "valid_m1 = torch.tensor(valid_m1)\n",
    "valid_x2 = torch.tensor(valid_x2)\n",
    "valid_m2 = torch.tensor(valid_m2)\n",
    "valid_x3 = torch.tensor(valid_x3)\n",
    "valid_m3 = torch.tensor(valid_m3)\n",
    "valid_y = torch.tensor(valid_y)\n",
    "\n",
    "valid_data = TensorDataset(valid_x1, valid_m1, valid_x2, valid_m2, valid_x3, valid_m3, valid_y)\n",
    "valid_sampler = list(range(len(valid_data)))\n",
    "valid_sampler = RandomSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "#### test data\n",
    "test_code_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in test_code]\n",
    "test_nat_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in test_nat]\n",
    "test_tags_dict = [tokenizer(t, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH, return_special_tokens_mask=True) for t in test_tags]\n",
    "test_code_ids = [text_id['input_ids'] for text_id in test_code_dict]\n",
    "test_code_masks = [text_id['attention_mask'] for text_id in test_code_dict]\n",
    "test_nat_ids = [text_id['input_ids'] for text_id in test_nat_dict]\n",
    "test_nat_masks = [text_id['attention_mask'] for text_id in test_nat_dict]\n",
    "test_tag_ids = [text_id['input_ids'] for text_id in test_tags_dict]\n",
    "test_tag_masks = [text_id['attention_mask'] for text_id in test_tags_dict]\n",
    "\n",
    "test_x1, test_m1, test_x2, test_m2, test_x3, test_m3, test_y = test_code_ids, test_code_masks, test_nat_ids, test_nat_masks, test_tag_ids, test_tag_masks, test_labels\n",
    "test_x1 = torch.tensor(test_x1)\n",
    "test_m1 = torch.tensor(test_m1)\n",
    "test_x2 = torch.tensor(test_x2)\n",
    "test_m2 = torch.tensor(test_m2)\n",
    "test_x3 = torch.tensor(test_x3)\n",
    "test_m3 = torch.tensor(test_m3)\n",
    "test_y = torch.tensor(test_y)\n",
    "\n",
    "test_data = TensorDataset(test_x1, test_m1, test_x2, test_m2, test_x3, test_m3, test_y)\n",
    "test_sampler = list(range(len(test_data)))\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "\n",
    "class VulT6_Classifier(nn.Module):\n",
    "    def __init__(self, encoder, tokenizer, config, num_labels): \n",
    "        super(VulT6_Classifier,self).__init__() \n",
    "        self.num_labels = num_labels \n",
    "        self.encoder = encoder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        self.classifier = nn.Linear(config.hidden_size * 3, num_labels)\n",
    "        \n",
    "    def get_t5_vec(self, source_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=source_ids, attention_mask=attention_mask, \n",
    "                               decoder_input_ids=source_ids, decoder_attention_mask=attention_mask, output_hidden_states=True)\n",
    "        hidden_states = outputs['decoder_hidden_states'][-1]\n",
    "        eos_mask = source_ids.eq(self.config.eos_token_id)\n",
    "        if len(torch.unique(eos_mask.sum(1))) > 1:\n",
    "            raise ValueError(\"All examples must have the same number of <eos> tokens.\")\n",
    "        vec = hidden_states[eos_mask, :].view(hidden_states.size(0), -1,\n",
    "                                              hidden_states.size(-1))[:, -1, :]\n",
    "        return vec\n",
    "    \n",
    "    def forward(self, x1, m1, x2, m2, x3, m3, labels=None):\n",
    "        vec_1 = self.get_t5_vec(x1, m1)\n",
    "        vec_2 = self.get_t5_vec(x2, m2)\n",
    "        vec_3 = self.get_t5_vec(x3, m3)\n",
    "        # batch_size x 768 (hidden_size)\n",
    "        # print(vec_code.shape)\n",
    "        all_concatenated = torch.cat([vec_1, vec_2, vec_3], dim=1)\n",
    "\n",
    "        logits = self.classifier(all_concatenated)\n",
    "        prob = nn.functional.softmax(logits)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            \n",
    "        return (loss, prob), None\n",
    "        #return (loss, final_logits), final_attention_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_txt(vult_model_path)\n",
    "encoder_model = transformers.T5ForConditionalGeneration.from_pretrained(vult_model_path)\n",
    "model_config = transformers.T5Config.from_pretrained(vult_model_path)    \n",
    "\n",
    "model = VulT6_Classifier(encoder_model, tokenizer, model_config, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.2},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "multi_gpu = torch.cuda.device_count() \n",
    "if multi_gpu > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "# model = nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2, num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations:  250\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed_val = 111\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "import pickle\n",
    "import os\n",
    "# save model \n",
    "def save_model(model, train_losses, val_losses, out_dir_model):\n",
    "    if not os.path.exists(out_dir_model):\n",
    "        os.makedirs(out_dir_model)\n",
    "    PATH = os.path.join(out_dir_model, 'VulTBinaryClassification.pt')\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    with open(out_dir_model + '/train_losses.pkl', 'wb') as f:\n",
    "        pickle.dump(train_losses, f)\n",
    "    with open(out_dir_model + '/val_losses.pkl', 'wb') as f:\n",
    "        pickle.dump(val_losses, f)\n",
    "print('number of iterations: ', len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_epochs:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_604/1081882820.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = nn.functional.softmax(logits)\n",
      "/scratch/conda_envs/dna/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "250it [06:51,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss after itaration 1: 3.620058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [02:16,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after itaration 1: 2.425647\n",
      "val_losses:  [] 2.4256465435028076\n",
      "Time: 9m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:52,  1.63s/it]"
     ]
    }
   ],
   "source": [
    "if not test_only:\n",
    "    from tqdm import tqdm\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    num_mb_train = len(train_dataloader)\n",
    "    num_mb_val = len(valid_dataloader)\n",
    "    current_step = 0\n",
    "    saved_steps = []\n",
    "    if num_mb_val == 0:\n",
    "        num_mb_val = 1\n",
    "\n",
    "    # print('number of iterations: ', len(train_dataloader), len(train_loader_extracted))\n",
    "    print('num_epochs: ', num_epochs)\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    for n in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        #for k, (data1, data2) in enumerate(zip(train_dataloader, train_loader_extracted)):\n",
    "        for k, (x1, m1, x2, m2, x3, m3, y) in tqdm(enumerate(train_dataloader)):\n",
    "            #mb_x, mb_m, mb_y = data1\n",
    "            # 56 features\n",
    "            #ex, ey, e_index = data2\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            x1 = x1.cuda()\n",
    "            m1 = m1.cuda()\n",
    "            x2 = x2.cuda()\n",
    "            m2 = m2.cuda()\n",
    "            x3 = x3.cuda()\n",
    "            m3 = m3.cuda()\n",
    "            y = y.cuda()\n",
    "            outputs, _, = model(x1, m1, x2, m2, x3, m3, labels=y)\n",
    "            loss = outputs[0]\n",
    "            # logits = outputs[1]\n",
    "            if multi_gpu > 1:\n",
    "                loss = loss.sum()\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            current_step += 1\n",
    "            train_loss += loss.data / num_mb_train\n",
    "\n",
    "            if current_step % save_step_at == 0:\n",
    "                saved_steps.append(current_step)\n",
    "                out_dir_model = os.path.join(out_dir, 'classification_model_{}'.format(saved_steps[-1]) )\n",
    "                print('saved as: ', out_dir_model)\n",
    "                if len(saved_steps) > max_step_saves:\n",
    "                    delete_dir = os.path.join(out_dir, 'classification_model_{}'.format(saved_steps[-(max_step_saves+1)]))\n",
    "                    os.system('rm -r {}'.format(delete_dir))\n",
    "                save_model(model, train_losses, val_losses, out_dir_model)\n",
    "\n",
    "\n",
    "        print (\"\\nTrain loss after itaration %i: %f\" % (n+1, train_loss))\n",
    "        train_losses.append(train_loss.cpu())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for k, (x1, m1, x2, m2, x3, m3, y) in tqdm(enumerate(valid_dataloader)):\n",
    "                x1 = x1.cuda()\n",
    "                m1 = m1.cuda()\n",
    "                x2 = x2.cuda()\n",
    "                m2 = m2.cuda()\n",
    "                x3 = x3.cuda()\n",
    "                m3 = m3.cuda()\n",
    "                y = y.cuda()\n",
    "                outputs, _, = model(x1, m1, x2, m2, x3, m3, labels=y)\n",
    "                \n",
    "                loss = outputs[0]\n",
    "                if multi_gpu > 1:\n",
    "                    loss = loss.sum()\n",
    "                #loss = model_loss(outputs[1], mb_y)\n",
    "\n",
    "                val_loss += loss.data / num_mb_val\n",
    "\n",
    "            print (\"Validation loss after itaration %i: %f\" % (n+1, val_loss))\n",
    "            # save the best\n",
    "\n",
    "            print('val_losses: ', val_losses, float(val_loss.cpu()))\n",
    "            if val_losses and float(val_loss.cpu()) <= min(val_losses):\n",
    "                out_dir_model = os.path.join(out_dir, 'classification_model_best')\n",
    "                print('the best model updated')\n",
    "                print('saved as: ', out_dir_model)\n",
    "                save_model(model, train_losses, val_losses, out_dir_model)\n",
    "            val_losses.append(float(val_loss.cpu()))\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        print(f'Time: {epoch_mins}m {epoch_secs}s')\n",
    "        if len(val_losses) > early_stop and float(val_loss.cpu()) > max(val_losses[-early_stop:-1]):\n",
    "            break\n",
    "\n",
    "    out_dir_model = os.path.join(out_dir, 'classification_model_last')\n",
    "    save_model(model, train_losses, val_losses, out_dir_model)\n",
    "    print('model saved as: ', out_dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# out_dir_model = '{}/classification_model_4000'.format(out_dir)\n",
    "\n",
    "test_dir_model = '{}/classification_model_last'.format(out_dir)\n",
    "\n",
    "PATH = os.path.join(test_dir_model, 'VulTBinaryClassification.pt')\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "with open(test_dir_model + '/train_losses.pkl', 'rb') as f:\n",
    "    train_losses = pickle.load(f)\n",
    "    \n",
    "with open(test_dir_model + '/val_losses.pkl', 'rb') as f:\n",
    "    val_losses = pickle.load(f)\n",
    "\n",
    "print(val_losses)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.savefig(os.path.join(out_dir, 'train_valid_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "print('num of iterations: ', len(test_dataloader))\n",
    "with torch.no_grad():\n",
    "    for k, (x1, m1, x2, m2, x3, m3, y) in tqdm(enumerate(test_dataloader)):\n",
    "        x1 = x1.cuda()\n",
    "        m1 = m1.cuda()\n",
    "        x2 = x2.cuda()\n",
    "        m2 = m2.cuda()\n",
    "        x3 = x3.cuda()\n",
    "        m3 = m3.cuda()\n",
    "        y = y.cuda()\n",
    "        output, _, = model(x1, m1, x2, m2, x3, m3, labels=y)\n",
    "        outputs.append(output[1].to('cpu'))\n",
    "outputs = torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[:10])\n",
    "print(test_y[:10])\n",
    "true_values = test_y.numpy()\n",
    "################################################\n",
    "## OPTIONAL: to find best detection threshold ##\n",
    "results = []\n",
    "for i in range(100):\n",
    "    prediction_probs = outputs[:,1]\n",
    "    detection_threshold = i / 100\n",
    "    predictions = [1 if x >= detection_threshold else 0 for x in list(prediction_probs)]\n",
    "    test_accuracy = np.sum(predictions == true_values) / len(true_values)\n",
    "    results.append(test_accuracy)\n",
    "results = sorted(results)\n",
    "print('lowest: ', results[:5])\n",
    "print('highest: ', results[-5:])\n",
    "################################################\n",
    "\n",
    "preds = outputs[:, 1] > 0.5\n",
    "eval_acc = np.mean(true_values == preds)\n",
    "print (\"Test Accuracy - eval_acc: \", eval_acc)\n",
    "\n",
    "_, predicted_values = torch.max(outputs, 1)\n",
    "predicted_values = predicted_values.numpy()\n",
    "test_accuracy = np.sum(predicted_values == true_values) / len(true_values)\n",
    "print (\"Test Accuracy:\", test_accuracy)\n",
    "log_txt(\"Test Accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# plot confusion matrix\n",
    "# code borrowed from scikit-learn.org\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "label_values = [0, 1]\n",
    "def confusion_matrix_scorer(y_pred, y):\n",
    "    cm = metrics.confusion_matrix(y, y_pred)\n",
    "    return {'tn': cm[0, 0], 'fp': cm[0, 1],\n",
    "        'fn': cm[1, 0], 'tp': cm[1, 1]}\n",
    "\n",
    "cm_test = metrics.confusion_matrix(true_values, predicted_values)\n",
    "print({ 'tn': cm_test[0, 0], 'fp': cm_test[0, 1],\n",
    "        'fn': cm_test[1, 0], 'tp': cm_test[1, 1]})\n",
    "\n",
    "log_txt('tn: {} - fp: {} - fn: {} - tp: {}'.format(cm_test[0, 0], cm_test[0, 1], cm_test[1, 0], cm_test[1, 1]))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm_test, classes=label_values, title='Confusion Matrix - Test Dataset')\n",
    "\n",
    "plt.savefig(os.path.join(out_dir, 'confusion_matrix.png'))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm_test, classes=label_values, title='Confusion Matrix - Test Dataset', normalize=True)\n",
    "\n",
    "plt.savefig(os.path.join(out_dir, 'confusion_matrix_normalized.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c75abca8982309fe1c90fd271b3e57a2ca520cb83e0a4572b1bde9aeb1619088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
